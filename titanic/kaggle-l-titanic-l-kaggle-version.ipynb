{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30635,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-20T20:22:00.424234Z","iopub.execute_input":"2024-01-20T20:22:00.425471Z","iopub.status.idle":"2024-01-20T20:22:00.883661Z","shell.execute_reply.started":"2024-01-20T20:22:00.425409Z","shell.execute_reply":"2024-01-20T20:22:00.882737Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:22:00.885530Z","iopub.execute_input":"2024-01-20T20:22:00.886749Z","iopub.status.idle":"2024-01-20T20:22:16.764536Z","shell.execute_reply.started":"2024-01-20T20:22:00.886702Z","shell.execute_reply":"2024-01-20T20:22:16.763544Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"print(f\"Found TF-DF {tf.__version__}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:22:25.251442Z","iopub.execute_input":"2024-01-20T20:22:25.252453Z","iopub.status.idle":"2024-01-20T20:22:25.262394Z","shell.execute_reply.started":"2024-01-20T20:22:25.252417Z","shell.execute_reply":"2024-01-20T20:22:25.260743Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Found TF-DF 2.13.0\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:25:16.939093Z","iopub.execute_input":"2024-01-20T20:25:16.940117Z","iopub.status.idle":"2024-01-20T20:25:17.017755Z","shell.execute_reply.started":"2024-01-20T20:25:16.940078Z","shell.execute_reply":"2024-01-20T20:25:17.016331Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                  Name     Sex   Age  SibSp  \\\n0                              Braund, Mr. Owen Harris    male  22.0      1   \n1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                               Heikkinen, Miss. Laina  female  26.0      0   \n3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                             Allen, Mr. William Henry    male  35.0      0   \n..                                                 ...     ...   ...    ...   \n886                              Montvila, Rev. Juozas    male  27.0      0   \n887                       Graham, Miss. Margaret Edith  female  19.0      0   \n888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n889                              Behr, Mr. Karl Howell    male  26.0      0   \n890                                Dooley, Mr. Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked  \n0        0         A/5 21171   7.2500   NaN        S  \n1        0          PC 17599  71.2833   C85        C  \n2        0  STON/O2. 3101282   7.9250   NaN        S  \n3        0            113803  53.1000  C123        S  \n4        0            373450   8.0500   NaN        S  \n..     ...               ...      ...   ...      ...  \n886      0            211536  13.0000   NaN        S  \n887      0            112053  30.0000   B42        S  \n888      2        W./C. 6607  23.4500   NaN        S  \n889      0            111369  30.0000  C148        C  \n890      0            370376   7.7500   NaN        Q  \n\n[891 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen, Mr. William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila, Rev. Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham, Miss. Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr, Mr. Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley, Mr. Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n        \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)                     \n    return df\n    \npreprocessed_train_df = preprocess(train_df)\npreprocessed_test_df = preprocess(test_df)\n\npreprocessed_train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:25:50.184166Z","iopub.execute_input":"2024-01-20T20:25:50.184592Z","iopub.status.idle":"2024-01-20T20:25:50.227057Z","shell.execute_reply.started":"2024-01-20T20:25:50.184562Z","shell.execute_reply":"2024-01-20T20:25:50.225418Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                              Name     Sex   Age  SibSp  \\\n0                            Braund Mr Owen Harris    male  22.0      1   \n1  Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                             Heikkinen Miss Laina  female  26.0      0   \n3         Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                           Allen Mr William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n0      0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1      0          PC 17599  71.2833   C85        C         17599          PC  \n2      0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3      0            113803  53.1000  C123        S        113803        NONE  \n4      0            373450   8.0500   NaN        S        373450        NONE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_number</th>\n      <th>Ticket_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preprocessed_train_df","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:25:58.853420Z","iopub.execute_input":"2024-01-20T20:25:58.853903Z","iopub.status.idle":"2024-01-20T20:25:58.883818Z","shell.execute_reply.started":"2024-01-20T20:25:58.853868Z","shell.execute_reply":"2024-01-20T20:25:58.882530Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"     PassengerId  Survived  Pclass  \\\n0              1         0       3   \n1              2         1       1   \n2              3         1       3   \n3              4         1       1   \n4              5         0       3   \n..           ...       ...     ...   \n886          887         0       2   \n887          888         1       1   \n888          889         0       3   \n889          890         1       1   \n890          891         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                              Braund Mr Owen Harris    male  22.0      1   \n1    Cumings Mrs John Bradley Florence Briggs Thayer  female  38.0      1   \n2                               Heikkinen Miss Laina  female  26.0      0   \n3           Futrelle Mrs Jacques Heath Lily May Peel  female  35.0      1   \n4                             Allen Mr William Henry    male  35.0      0   \n..                                               ...     ...   ...    ...   \n886                              Montvila Rev Juozas    male  27.0      0   \n887                       Graham Miss Margaret Edith  female  19.0      0   \n888             Johnston Miss Catherine Helen Carrie  female   NaN      1   \n889                              Behr Mr Karl Howell    male  26.0      0   \n890                                Dooley Mr Patrick    male  32.0      0   \n\n     Parch            Ticket     Fare Cabin Embarked Ticket_number Ticket_item  \n0        0         A/5 21171   7.2500   NaN        S         21171         A/5  \n1        0          PC 17599  71.2833   C85        C         17599          PC  \n2        0  STON/O2. 3101282   7.9250   NaN        S       3101282    STON/O2.  \n3        0            113803  53.1000  C123        S        113803        NONE  \n4        0            373450   8.0500   NaN        S        373450        NONE  \n..     ...               ...      ...   ...      ...           ...         ...  \n886      0            211536  13.0000   NaN        S        211536        NONE  \n887      0            112053  30.0000   B42        S        112053        NONE  \n888      2        W./C. 6607  23.4500   NaN        S          6607       W./C.  \n889      0            111369  30.0000  C148        C        111369        NONE  \n890      0            370376   7.7500   NaN        Q        370376        NONE  \n\n[891 rows x 14 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n      <th>Ticket_number</th>\n      <th>Ticket_item</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund Mr Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>21171</td>\n      <td>A/5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings Mrs John Bradley Florence Briggs Thayer</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n      <td>17599</td>\n      <td>PC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen Miss Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>3101282</td>\n      <td>STON/O2.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Futrelle Mrs Jacques Heath Lily May Peel</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>113803</td>\n      <td>53.1000</td>\n      <td>C123</td>\n      <td>S</td>\n      <td>113803</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Allen Mr William Henry</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>373450</td>\n      <td>8.0500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>373450</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>886</th>\n      <td>887</td>\n      <td>0</td>\n      <td>2</td>\n      <td>Montvila Rev Juozas</td>\n      <td>male</td>\n      <td>27.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>211536</td>\n      <td>13.0000</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>211536</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>887</th>\n      <td>888</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Graham Miss Margaret Edith</td>\n      <td>female</td>\n      <td>19.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>112053</td>\n      <td>30.0000</td>\n      <td>B42</td>\n      <td>S</td>\n      <td>112053</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>888</th>\n      <td>889</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Johnston Miss Catherine Helen Carrie</td>\n      <td>female</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>2</td>\n      <td>W./C. 6607</td>\n      <td>23.4500</td>\n      <td>NaN</td>\n      <td>S</td>\n      <td>6607</td>\n      <td>W./C.</td>\n    </tr>\n    <tr>\n      <th>889</th>\n      <td>890</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Behr Mr Karl Howell</td>\n      <td>male</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>111369</td>\n      <td>30.0000</td>\n      <td>C148</td>\n      <td>C</td>\n      <td>111369</td>\n      <td>NONE</td>\n    </tr>\n    <tr>\n      <th>890</th>\n      <td>891</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Dooley Mr Patrick</td>\n      <td>male</td>\n      <td>32.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>370376</td>\n      <td>7.7500</td>\n      <td>NaN</td>\n      <td>Q</td>\n      <td>370376</td>\n      <td>NONE</td>\n    </tr>\n  </tbody>\n</table>\n<p>891 rows × 14 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"input_features = list(preprocessed_train_df.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n#input_features.remove(\"Ticket_number\")\n\nprint(f\"Input features: {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:26:06.997607Z","iopub.execute_input":"2024-01-20T20:26:06.998098Z","iopub.status.idle":"2024-01-20T20:26:07.006002Z","shell.execute_reply.started":"2024-01-20T20:26:06.998063Z","shell.execute_reply":"2024-01-20T20:26:07.004745Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Input features: ['Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Cabin', 'Embarked', 'Ticket_number', 'Ticket_item']\n","output_type":"stream"}]},{"cell_type":"code","source":"unique_counts = preprocessed_train_df[\"Ticket\"].nunique()\n\nprint(unique_counts)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:26:13.875607Z","iopub.execute_input":"2024-01-20T20:26:13.876039Z","iopub.status.idle":"2024-01-20T20:26:13.889579Z","shell.execute_reply.started":"2024-01-20T20:26:13.876005Z","shell.execute_reply":"2024-01-20T20:26:13.887910Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"681\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_names(features, labels=None):\n    \"\"\"Divite the names into tokens. TF-DF can consume text tokens natively.\"\"\"\n    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n    return features, labels\n\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df,label=\"Survived\").map(tokenize_names)\ntest_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_test_df).map(tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:26:38.604897Z","iopub.execute_input":"2024-01-20T20:26:38.606571Z","iopub.status.idle":"2024-01-20T20:26:38.798737Z","shell.execute_reply.started":"2024-01-20T20:26:38.606515Z","shell.execute_reply":"2024-01-20T20:26:38.797319Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_ds","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:27:47.538697Z","iopub.execute_input":"2024-01-20T20:27:47.539242Z","iopub.status.idle":"2024-01-20T20:27:47.548773Z","shell.execute_reply.started":"2024-01-20T20:27:47.539169Z","shell.execute_reply":"2024-01-20T20:27:47.547485Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"<_MapDataset element_spec=({'PassengerId': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Pclass': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Name': RaggedTensorSpec(TensorShape([None, None]), tf.string, 1, tf.int64), 'Sex': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Age': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'SibSp': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Parch': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Ticket': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Fare': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Cabin': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Embarked': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Ticket_number': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Ticket_item': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"},"metadata":{}}]},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    random_seed=1234,\n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:27:07.397023Z","iopub.execute_input":"2024-01-20T20:27:07.397569Z","iopub.status.idle":"2024-01-20T20:27:20.182835Z","shell.execute_reply.started":"2024-01-20T20:27:07.397532Z","shell.execute_reply":"2024-01-20T20:27:20.181060Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"[WARNING 24-01-20 20:27:07.4579 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-01-20 20:27:07.4583 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-01-20 20:27:07.4583 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 24-01-20 20:27:16.3957 UTC kernel.cc:1243] Loading model from path /tmp/tmpbqgovd0f/model/ with prefix a246a1dfac3249e9\n[INFO 24-01-20 20:27:16.4080 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesQuickScorerExtended\" built\n[INFO 24-01-20 20:27:16.4082 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7e73a376d750> and will run it as-is.\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\nCause: could not get source code\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\nAccuracy: 0.8260869383811951 Loss:0.8608942627906799\n","output_type":"stream"}]},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # Very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    \n    #num_trees=2000,\n    \n    # Only for GBT.\n    # A bit slower, but great to understand the model.\n    # compute_permutation_variable_importance=True,\n    \n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n    \n    min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n        sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234,\n    \n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:29:20.399080Z","iopub.execute_input":"2024-01-20T20:29:20.399614Z","iopub.status.idle":"2024-01-20T20:29:22.029486Z","shell.execute_reply.started":"2024-01-20T20:29:20.399578Z","shell.execute_reply":"2024-01-20T20:29:22.028033Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"[WARNING 24-01-20 20:29:20.4195 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-01-20 20:29:20.4196 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-01-20 20:29:20.4197 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 24-01-20 20:29:21.6263 UTC kernel.cc:1243] Loading model from path /tmp/tmp24s7cvzw/model/ with prefix 9fccb6e432934367\n[INFO 24-01-20 20:29:21.6368 UTC decision_forest.cc:660] Model loaded with 42 root(s), 2212 node(s), and 10 input feature(s).\n[INFO 24-01-20 20:29:21.6369 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesGeneric\" built\n[INFO 24-01-20 20:29:21.6369 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.782608687877655 Loss:1.060815453529358\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:29:56.397726Z","iopub.execute_input":"2024-01-20T20:29:56.398377Z","iopub.status.idle":"2024-01-20T20:29:56.417471Z","shell.execute_reply.started":"2024-01-20T20:29:56.398327Z","shell.execute_reply":"2024-01-20T20:29:56.416263Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"gradient_boosted_trees_model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n=================================================================\nTotal params: 1 (1.00 Byte)\nTrainable params: 0 (0.00 Byte)\nNon-trainable params: 1 (1.00 Byte)\n_________________________________________________________________\nType: \"GRADIENT_BOOSTED_TREES\"\nTask: CLASSIFICATION\nLabel: \"__LABEL\"\n\nInput Features (11):\n\tAge\n\tCabin\n\tEmbarked\n\tFare\n\tName\n\tParch\n\tPclass\n\tSex\n\tSibSp\n\tTicket_item\n\tTicket_number\n\nNo weights\n\nVariable Importance: INV_MEAN_MIN_DEPTH:\n    1.           \"Sex\"  0.597073 ################\n    2.           \"Age\"  0.363764 #######\n    3.          \"Fare\"  0.264018 ###\n    4.          \"Name\"  0.207843 #\n    5.        \"Pclass\"  0.178906 \n    6. \"Ticket_number\"  0.178488 \n    7.   \"Ticket_item\"  0.177907 \n    8.      \"Embarked\"  0.177237 \n    9.         \"Parch\"  0.175481 \n   10.         \"SibSp\"  0.171800 \n\nVariable Importance: NUM_AS_ROOT:\n    1.  \"Sex\" 36.000000 ################\n    2. \"Name\"  6.000000 \n\nVariable Importance: NUM_NODES:\n    1.           \"Age\" 530.000000 ################\n    2.          \"Fare\" 311.000000 #########\n    3.          \"Name\" 66.000000 #\n    4.   \"Ticket_item\" 50.000000 #\n    5.           \"Sex\" 42.000000 #\n    6.         \"Parch\" 26.000000 \n    7. \"Ticket_number\" 21.000000 \n    8.        \"Pclass\" 17.000000 \n    9.      \"Embarked\" 16.000000 \n   10.         \"SibSp\"  6.000000 \n\nVariable Importance: SUM_SCORE:\n    1.           \"Sex\" 484.272240 ################\n    2.           \"Age\" 393.999352 #############\n    3.          \"Fare\" 323.250985 ##########\n    4.          \"Name\" 105.330212 ###\n    5.        \"Pclass\" 26.851849 \n    6.   \"Ticket_item\" 25.837695 \n    7. \"Ticket_number\" 17.652836 \n    8.      \"Embarked\"  9.217001 \n    9.         \"Parch\"  7.010211 \n   10.         \"SibSp\"  0.574055 \n\n\n\nLoss: BINOMIAL_LOG_LIKELIHOOD\nValidation loss value: 1.06082\nNumber of trees per iteration: 1\nNode format: NOT_SET\nNumber of trees: 42\nTotal number of nodes: 2212\n\nNumber of nodes by tree:\nCount: 42 Average: 52.6667 StdDev: 4.47036\nMin: 41 Max: 63 Ignored: 0\n----------------------------------------------\n[ 41, 42)  2   4.76%   4.76% ##\n[ 42, 43)  0   0.00%   4.76%\n[ 43, 44)  0   0.00%   4.76%\n[ 44, 45)  0   0.00%   4.76%\n[ 45, 46)  1   2.38%   7.14% #\n[ 46, 47)  0   0.00%   7.14%\n[ 47, 49)  2   4.76%  11.90% ##\n[ 49, 50)  5  11.90%  23.81% ####\n[ 50, 51)  0   0.00%  23.81%\n[ 51, 52)  4   9.52%  33.33% ###\n[ 52, 53)  0   0.00%  33.33%\n[ 53, 54) 13  30.95%  64.29% ##########\n[ 54, 55)  0   0.00%  64.29%\n[ 55, 57)  9  21.43%  85.71% #######\n[ 57, 58)  1   2.38%  88.10% #\n[ 58, 59)  0   0.00%  88.10%\n[ 59, 60)  3   7.14%  95.24% ##\n[ 60, 61)  0   0.00%  95.24%\n[ 61, 62)  1   2.38%  97.62% #\n[ 62, 63]  1   2.38% 100.00% #\n\nDepth by leafs:\nCount: 1127 Average: 4.8465 StdDev: 0.454147\nMin: 2 Max: 5 Ignored: 0\n----------------------------------------------\n[ 2, 3)   1   0.09%   0.09%\n[ 3, 4)  40   3.55%   3.64%\n[ 4, 5)  90   7.99%  11.62% #\n[ 5, 5] 996  88.38% 100.00% ##########\n\nNumber of training obs by leaf:\nCount: 1127 Average: 29.7764 StdDev: 71.9364\nMin: 1 Max: 467 Ignored: 0\n----------------------------------------------\n[   1,  24) 884  78.44%  78.44% ##########\n[  24,  47)  79   7.01%  85.45% #\n[  47,  71)  44   3.90%  89.35%\n[  71,  94)  19   1.69%  91.04%\n[  94, 117)  13   1.15%  92.19%\n[ 117, 141)  15   1.33%  93.52%\n[ 141, 164)  24   2.13%  95.65%\n[ 164, 187)   6   0.53%  96.18%\n[ 187, 211)   4   0.35%  96.54%\n[ 211, 234)   1   0.09%  96.63%\n[ 234, 257)   1   0.09%  96.72%\n[ 257, 281)   3   0.27%  96.98%\n[ 281, 304)   2   0.18%  97.16%\n[ 304, 327)   2   0.18%  97.34%\n[ 327, 351)   2   0.18%  97.52%\n[ 351, 374)  11   0.98%  98.49%\n[ 374, 397)   5   0.44%  98.94%\n[ 397, 421)   9   0.80%  99.73%\n[ 421, 444)   1   0.09%  99.82%\n[ 444, 467]   2   0.18% 100.00%\n\nAttribute in nodes:\n\t530 : Age [NUMERICAL]\n\t311 : Fare [NUMERICAL]\n\t66 : Name [CATEGORICAL_SET]\n\t50 : Ticket_item [CATEGORICAL]\n\t42 : Sex [CATEGORICAL]\n\t26 : Parch [NUMERICAL]\n\t21 : Ticket_number [CATEGORICAL]\n\t17 : Pclass [NUMERICAL]\n\t16 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 0:\n\t36 : Sex [CATEGORICAL]\n\t6 : Name [CATEGORICAL_SET]\n\nAttribute in nodes with depth <= 1:\n\t50 : Age [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t26 : Fare [NUMERICAL]\n\t7 : Name [CATEGORICAL_SET]\n\t5 : Pclass [NUMERICAL]\n\t2 : Ticket_number [CATEGORICAL]\n\nAttribute in nodes with depth <= 2:\n\t130 : Age [NUMERICAL]\n\t76 : Fare [NUMERICAL]\n\t36 : Sex [CATEGORICAL]\n\t19 : Name [CATEGORICAL_SET]\n\t8 : Ticket_number [CATEGORICAL]\n\t7 : Embarked [CATEGORICAL]\n\t6 : Pclass [NUMERICAL]\n\t6 : Parch [NUMERICAL]\n\t5 : Ticket_item [CATEGORICAL]\n\nAttribute in nodes with depth <= 3:\n\t270 : Age [NUMERICAL]\n\t173 : Fare [NUMERICAL]\n\t39 : Name [CATEGORICAL_SET]\n\t38 : Sex [CATEGORICAL]\n\t18 : Ticket_item [CATEGORICAL]\n\t13 : Ticket_number [CATEGORICAL]\n\t12 : Parch [NUMERICAL]\n\t12 : Embarked [CATEGORICAL]\n\t9 : Pclass [NUMERICAL]\n\t3 : SibSp [NUMERICAL]\n\nAttribute in nodes with depth <= 5:\n\t530 : Age [NUMERICAL]\n\t311 : Fare [NUMERICAL]\n\t66 : Name [CATEGORICAL_SET]\n\t50 : Ticket_item [CATEGORICAL]\n\t42 : Sex [CATEGORICAL]\n\t26 : Parch [NUMERICAL]\n\t21 : Ticket_number [CATEGORICAL]\n\t17 : Pclass [NUMERICAL]\n\t16 : Embarked [CATEGORICAL]\n\t6 : SibSp [NUMERICAL]\n\nCondition type in nodes:\n\t890 : ObliqueCondition\n\t145 : ContainsBitmapCondition\n\t50 : ContainsCondition\nCondition type in nodes with depth <= 0:\n\t40 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 1:\n\t81 : ObliqueCondition\n\t43 : ContainsBitmapCondition\n\t2 : ContainsCondition\nCondition type in nodes with depth <= 2:\n\t218 : ObliqueCondition\n\t62 : ContainsBitmapCondition\n\t13 : ContainsCondition\nCondition type in nodes with depth <= 3:\n\t467 : ObliqueCondition\n\t89 : ContainsBitmapCondition\n\t31 : ContainsCondition\nCondition type in nodes with depth <= 5:\n\t890 : ObliqueCondition\n\t145 : ContainsBitmapCondition\n\t50 : ContainsCondition\n\nTraining logs:\nNumber of iteration to final model: 42\n\tIter:1 train-loss:1.264594 valid-loss:1.360749  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:2 train-loss:1.210623 valid-loss:1.320363  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:3 train-loss:1.160657 valid-loss:1.281972  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:4 train-loss:1.116982 valid-loss:1.250548  train-accuracy:0.624531 valid-accuracy:0.543478\n\tIter:5 train-loss:1.075170 valid-loss:1.221467  train-accuracy:0.807259 valid-accuracy:0.760870\n\tIter:6 train-loss:1.035656 valid-loss:1.199482  train-accuracy:0.822278 valid-accuracy:0.760870\n\tIter:16 train-loss:0.787670 valid-loss:1.088161  train-accuracy:0.903630 valid-accuracy:0.771739\n\tIter:26 train-loss:0.648139 valid-loss:1.066864  train-accuracy:0.921151 valid-accuracy:0.782609\n\tIter:36 train-loss:0.559101 valid-loss:1.068122  train-accuracy:0.921151 valid-accuracy:0.782609\n\tIter:46 train-loss:0.496837 valid-loss:1.064204  train-accuracy:0.929912 valid-accuracy:0.771739\n\tIter:56 train-loss:0.451017 valid-loss:1.083011  train-accuracy:0.941176 valid-accuracy:0.771739\n\tIter:66 train-loss:0.415965 valid-loss:1.105307  train-accuracy:0.946183 valid-accuracy:0.771739\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def prediction_to_kaggle_format(model, threshold=0.5):\n    proba_survive = model.predict(test_ds, verbose=0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": (proba_survive >= threshold).astype(int)\n    })\n\ndef make_submission(kaggle_predictions):\n    path=\"/kaggle/working/submission.csv\"\n    kaggle_predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n    \nkaggle_predictions = prediction_to_kaggle_format(model)\nmake_submission(kaggle_predictions)\n!head /kaggle/working/submission.csv","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:31:15.291875Z","iopub.execute_input":"2024-01-20T20:31:15.292399Z","iopub.status.idle":"2024-01-20T20:31:16.601988Z","shell.execute_reply.started":"2024-01-20T20:31:15.292356Z","shell.execute_reply":"2024-01-20T20:31:16.599752Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Submission exported to /kaggle/working/submission.csv\nPassengerId,Survived\n892,0\n893,0\n894,0\n895,0\n896,0\n897,0\n898,0\n899,0\n900,1\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner = tfdf.tuner.RandomSearch(num_trials=1000)\ntuner.choice(\"min_examples\", [2, 5, 7, 10])\ntuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n\nlocal_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\nlocal_search_space.choice(\"max_depth\", [3, 4, 5, 6, 8])\n\nglobal_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\nglobal_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 256])\n\n#tuner.choice(\"use_hessian_gain\", [True, False])\ntuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\ntuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n\n\ntuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\noblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\noblique_space.choice(\"sparse_oblique_normalization\",\n                     [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\noblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\noblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n\n# Tune the model. Notice the `tuner=tuner`.\ntuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\ntuned_model.fit(train_ds, verbose=0)\n\ntuned_self_evaluation = tuned_model.make_inspector().evaluation()\nprint(f\"Accuracy: {tuned_self_evaluation.accuracy} Loss:{tuned_self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-20T20:32:10.155482Z","iopub.execute_input":"2024-01-20T20:32:10.156047Z","iopub.status.idle":"2024-01-20T20:34:14.846400Z","shell.execute_reply.started":"2024-01-20T20:32:10.156001Z","shell.execute_reply":"2024-01-20T20:34:14.845000Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"Use /tmp/tmpn4uildp0 as temporary training directory\n","output_type":"stream"},{"name":"stderr","text":"[WARNING 24-01-20 20:32:10.1955 UTC gradient_boosted_trees.cc:1818] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-01-20 20:32:10.1955 UTC gradient_boosted_trees.cc:1829] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n[WARNING 24-01-20 20:32:10.1956 UTC gradient_boosted_trees.cc:1843] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n[INFO 24-01-20 20:34:13.8660 UTC kernel.cc:1243] Loading model from path /tmp/tmpn4uildp0/model/ with prefix f7eb74db1b8e4a55\n[INFO 24-01-20 20:34:13.8857 UTC decision_forest.cc:660] Model loaded with 32 root(s), 852 node(s), and 12 input feature(s).\n[INFO 24-01-20 20:34:13.8860 UTC abstract_model.cc:1311] Engine \"GradientBoostedTreesGeneric\" built\n[INFO 24-01-20 20:34:13.8864 UTC kernel.cc:1075] Use fast generic engine\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.8630136847496033 Loss:0.6804219484329224\n","output_type":"stream"}]},{"cell_type":"code","source":"predictions = None\nnum_predictions = 0\n\nfor i in range(100):\n    print(f\"i:{i}\")\n    # Possible models: GradientBoostedTreesModel or RandomForestModel\n    model = tfdf.keras.GradientBoostedTreesModel(\n        verbose=0, # Very few logs\n        features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n        exclude_non_specified_features=True, # Only use the features in \"features\"\n\n        #min_examples=1,\n        #categorical_algorithm=\"RANDOM\",\n        ##max_depth=4,\n        #shrinkage=0.05,\n        ##num_candidate_attributes_ratio=0.2,\n        #split_axis=\"SPARSE_OBLIQUE\",\n        #sparse_oblique_normalization=\"MIN_MAX\",\n        #sparse_oblique_num_projections_exponent=2.0,\n        #num_trees=2000,\n        ##validation_ratio=0.0,\n        random_seed=i,\n        honest=True,\n    )\n    model.fit(train_ds)\n    \n    sub_predictions = model.predict(serving_ds, verbose=0)[:,0]\n    if predictions is None:\n        predictions = sub_predictions\n    else:\n        predictions += sub_predictions\n    num_predictions += 1\n\npredictions/=num_predictions\n\nkaggle_predictions = pd.DataFrame({\n        \"PassengerId\": serving_df[\"PassengerId\"],\n        \"Survived\": (predictions >= 0.5).astype(int)\n    })\n\nmake_submission(kaggle_predictions)","metadata":{},"execution_count":null,"outputs":[]}]}